{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from reduce_size_df import reduce_mem_usage\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, skew \n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import scipy.stats\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader,Dataset\n",
    "#from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline,SVD\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "#pip install git+https://github.com/gbolmier/funk-svd\n",
    "from numba import njit\n",
    "from funk_svd.dataset import fetch_ml_ratings\n",
    "from funk_svd import SVD\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'ydata-ymovies-user-movie-ratings-train-v1_0.txt.gz',sep='\\t',compression='gzip',encoding='latin-1',header=None)\n",
    "df_test=pd.read_csv(r'ydata-ymovies-user-movie-ratings-test-v1_0.txt.gz',sep='\\t',compression='gzip',encoding='latin-1',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 6.45 MB\n",
      "Memory usage after optimization is: 1.61 MB\n",
      "Decreased by 75.0%\n",
      "Memory usage of dataframe is 0.31 MB\n",
      "Memory usage after optimization is: 0.08 MB\n",
      "Decreased by 75.0%\n"
     ]
    }
   ],
   "source": [
    "df1=reduce_mem_usage(df)\n",
    "df_test1=reduce_mem_usage(df_test)\n",
    "df1.rename(columns={0: 'u_id', 1: 'i_id',3:'rating'},inplace=True)\n",
    "df1.drop(2,axis='columns',inplace=True)\n",
    "df_test1.rename(columns={0: 'u_id', 1: 'i_id',3:'rating'},inplace=True)\n",
    "df_test1.drop(2,axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>i_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1800029049</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1804857429</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1800030906</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1800018548</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1800256362</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   u_id        i_id  rating\n",
       "0     1  1800029049       5\n",
       "1     1  1804857429       4\n",
       "2     1  1800030906       5\n",
       "3     1  1800018548       5\n",
       "4     1  1800256362       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# source - https://github.com/gbolmier/funk-svd/tree/master/funk_svd( my contribution little modificatins and additional mappings)\n",
    "\n",
    "def _preprocess_data(X):\n",
    "\n",
    "        X = X.copy()\n",
    "        #X_test=X_test.copy()\n",
    " # Mappings have to be created\n",
    "        #X.sort_values(by=[)\n",
    "        user_ids = X['u_id'].unique().tolist()\n",
    "        item_ids = X['i_id'].unique().tolist()\n",
    "\n",
    "        n_users = len(user_ids)\n",
    "        n_items = len(item_ids)\n",
    "\n",
    "        user_idx = range(n_users)\n",
    "        item_idx = range(n_items)\n",
    "\n",
    "        user_mapping_ = dict(zip(user_ids, user_idx))\n",
    "        item_mapping_ = dict(zip(item_ids, item_idx))\n",
    "\n",
    "        X['u_id'] = X['u_id'].map(user_mapping_)\n",
    "        X['i_id'] = X['i_id'].map(item_mapping_)\n",
    "        #X_test['u_MAP'] = X_test['u_id'].map(user_mapping_)\n",
    "        #X_test['i_MAP'] = X_test['i_id'].map(item_mapping_)\n",
    "\n",
    "        # Tag validation set unknown users/items with -1 (enables\n",
    "        # `fast_methods._compute_val_metrics` detecting them)\n",
    "        X.fillna(-1, inplace=True)\n",
    "        #X_test.fillna(-1, inplace=True)\n",
    "        X['u_id'] = X['u_id'].astype(np.int32)\n",
    "        X['i_id'] = X['i_id'].astype(np.int32)\n",
    "        #X_test['u_id'] = X_test['u_id'].astype(np.int32)\n",
    "        #X_test['i_id'] = X_test['i_id'].astype(np.int32)\n",
    "        return X[['u_id','i_id','rating']].values,user_mapping_,item_mapping_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validation_rmse(global_mean1,b_user,b_item,P,V,test_data,user_map,item_map):\n",
    "    error=[]\n",
    "    test_globalmean=test_data[:,2].sum()/test_data.shape[0]\n",
    "    for i in range(test_data.shape[0]):\n",
    "        user,item,rating= user_map[test_data[i,0]],item_map[test_data[i,1]],int(test_data[i,2])\n",
    "        pred=test_globalmean+b_user[user]+b_item[item]+np.dot(P[user,:],V[:,item])\n",
    "        error.append(rating-pred)\n",
    "    residuals=np.array(error)\n",
    "    loss= np.square(residuals).mean()\n",
    "    rmse = np.sqrt(loss)\n",
    "    return rmse\n",
    "\n",
    "def training_rmse(global_mean1,b_user,b_item,P,V,training_data,user_map,item_map):\n",
    "    error=[]\n",
    "    for i in range(training_data.shape[0]):\n",
    "        user,item,rating= training_data[i,0],training_data[i,1],training_data[i,2]\n",
    "        pred=global_mean1+b_user[user]+b_item[item]+np.dot(P[user,:],V[:,item])\n",
    "        error.append(rating-pred)\n",
    "    residuals=np.array(error)\n",
    "    loss= np.square(residuals).mean()\n",
    "    rmse = np.sqrt(loss)\n",
    "    return rmse\n",
    "\n",
    "class rec():\n",
    "    def __init__(self,train,learning_rate,features,beta,iterations,test,max_rating,min_rating):\n",
    "        self.training_data,self.user_map,self.item_map=_preprocess_data(train)\n",
    "        self.test=np.array(df_test)\n",
    "        users_count = len(np.unique(self.training_data[:, 0]))\n",
    "        items_count = len(np.unique(self.training_data[:, 1]))\n",
    "        self.b_user = np.zeros(users_count)\n",
    "        self.b_item = np.zeros(items_count)\n",
    "        self.features=features\n",
    "        self.learning_rate=learning_rate\n",
    "        self.iterations=iterations\n",
    "        self.beta=beta\n",
    "        self.P=np.random.normal(0,0.1,(users_count, self.features))\n",
    "        self.V=np.random.normal(0,0.1,(self.features,items_count))\n",
    "        self.b=self.training_data[:,2].sum()/self.training_data.shape[0]\n",
    "        self.max_rating=max_rating\n",
    "        self.min_rating=min_rating\n",
    "    \n",
    "    def run_sgd(self):\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        for i in range(self.training_data.shape[0]):\n",
    "            user,item,rating=int(self.training_data[i,0]),int(self.training_data[i,1]),int(self.training_data[i,2])\n",
    "            pred_rating=self.b+self.b_user[user]+self.b_item[item] + np.dot(self.P[user,:],self.V[:,item])\n",
    "            error = rating - pred_rating\n",
    "            old_user=self.b_user[user]\n",
    "            old_item=self.b_item[item]\n",
    "            self.b_user[user]=self.b_user[user]+self.learning_rate*(error - self.beta*old_user)\n",
    "            self.b_item[item]=self.b_item[item]+self.learning_rate*(error - self.beta*old_item)\n",
    "\n",
    "            #lasso regularization l2\n",
    "\n",
    "            old_pi=self.P[user,:]\n",
    "            old_vi=self.V[:,item]\n",
    "            self.P[user,:]=self.P[user,:]+self.learning_rate*(error*old_vi - self.beta*old_pi)\n",
    "            self.V[:,item]=self.V[:,item]+self.learning_rate*(error*old_pi - self.beta*old_vi)\n",
    "\n",
    "    def train(self):\n",
    "        for i in range(self.iterations):\n",
    "            start = time.time()\n",
    "            self.run_sgd()\n",
    "            if (i+1) % 10 == 0:\n",
    "                val_rmse=validation_rmse(self.b,self.b_user,self.b_item,self.P,self.V,self.test,self.user_map,self.item_map)\n",
    "                train_rmse=training_rmse(self.b,self.b_user,self.b_item,self.P,self.V,self.training_data,self.user_map,self.item_map)                \n",
    "                end = time.time()\n",
    "                print(\"Iteration: %d ;train_RMSE =%.4f ;  val_RMSE = %.4f ; time=%.4f\" % (i+1,train_rmse, val_rmse,(end-start)))\n",
    "                \n",
    "                \n",
    "    def full_matrix(self):\n",
    "        return self.b + self.b_user.reshape(-1,1) + self.b_item.reshape(1,-1)+ np.dot(self.P,self.V)\n",
    "    \n",
    "    \n",
    "    def clip_predict(self,actual_Rat):\n",
    "        if actual_Rat>self.max_rating:\n",
    "            pred=self.max_rating\n",
    "        else:\n",
    "            pred=self.actual_Rat\n",
    "        if actual_Rat<self.min_rating:\n",
    "            pred=self.min_rating\n",
    "        else:\n",
    "            pred=actual_Rat\n",
    "        return pred\n",
    "\n",
    "    def predict_user_movie(self,data_type,dataframe,user,item,clip=True):\n",
    "        if data_type=='test':\n",
    "            s=np.array(dataframe)\n",
    "            test_globalmean=s[:,2].sum()/s.shape[0]\n",
    "            if user in self.user_map and item in self.item_map:   \n",
    "                user1,item1=self.user_map[user],self.item_map[item]\n",
    "                self.actual_Rat=test_globalmean+ self.b_user[user1]+ self.b_item[item1]+np.dot(self.P[user1,:],self.V[:,item1])\n",
    "                if clip is True:\n",
    "                    return self.clip_predict(self.actual_Rat)\n",
    "            else:\n",
    "                print('user or item not known, the avg rating is')\n",
    "                return test_globalmean\n",
    "        elif data_type=='train':\n",
    "                user1,item1=self.user_map[user],self.item_map[item]\n",
    "                self.actual_Rat= self.b+ self.b_user[user1]+ self.b_item[item1]+np.dot(self.P[user1,:],self.V[:,item1])\n",
    "                if clip is True:\n",
    "                    return self.clip_predict(self.actual_Rat)\n",
    "\n",
    "            \n",
    "    \n",
    "    def predict_dataset(self,dataframe):\n",
    "            rating=[]\n",
    "            d=np.array(dataframe)\n",
    "            for i in d.shape[0]:\n",
    "                user,item=d[i,0].d[i,2]\n",
    "                rating.append(self.predict_user_movie('test',dataframe,user,item,clip=True))\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rec=rec(train=df,  learning_rate=0.01,  features=15, beta =0.005,iterations=100,test=df_test,\n",
    "       max_rating=5,min_rating=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ;train_RMSE =0.7910 ;  val_RMSE = 0.9825 ; time=4.9369\n",
      "Iteration: 20 ;train_RMSE =0.6272 ;  val_RMSE = 1.0288 ; time=4.9494\n"
     ]
    }
   ],
   "source": [
    "Rec.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>i_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1807428619</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1807858487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>1808403981</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3</td>\n",
       "      <td>1807463608</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>1804398724</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    u_id        i_id  rating\n",
       "6      1  1807428619       3\n",
       "12     1  1807858487       3\n",
       "18     2  1808403981       3\n",
       "55     3  1807463608       3\n",
       "60     3  1804398724       3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rating']==3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clip_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-7cf87d5635dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_user_movie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-3bbbdbb22da1>\u001b[0m in \u001b[0;36mpredict_user_movie\u001b[0;34m(self, data_type, dataframe, user, item, clip)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_Rat\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_user\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mclip\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mclip_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_Rat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clip_predict' is not defined"
     ]
    }
   ],
   "source": [
    "Rec.predict_user_movie('train',df_test,1,2,clip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "Epoch 1/100  | val_loss: 1.31 - val_rmse: 1.14 - val_mae: 0.87 - took 0.1 sec\n",
      "Epoch 2/100  | val_loss: 1.25 - val_rmse: 1.12 - val_mae: 0.85 - took 0.0 sec\n",
      "Epoch 3/100  | val_loss: 1.21 - val_rmse: 1.10 - val_mae: 0.83 - took 0.0 sec\n",
      "Epoch 4/100  | val_loss: 1.18 - val_rmse: 1.09 - val_mae: 0.82 - took 0.0 sec\n",
      "Epoch 5/100  | val_loss: 1.16 - val_rmse: 1.08 - val_mae: 0.81 - took 0.0 sec\n",
      "Epoch 6/100  | val_loss: 1.14 - val_rmse: 1.07 - val_mae: 0.81 - took 0.0 sec\n",
      "Epoch 7/100  | val_loss: 1.13 - val_rmse: 1.06 - val_mae: 0.80 - took 0.0 sec\n",
      "Epoch 8/100  | val_loss: 1.11 - val_rmse: 1.06 - val_mae: 0.79 - took 0.0 sec\n",
      "Epoch 9/100  | val_loss: 1.10 - val_rmse: 1.05 - val_mae: 0.79 - took 0.0 sec\n",
      "Epoch 10/100 | val_loss: 1.09 - val_rmse: 1.04 - val_mae: 0.78 - took 0.0 sec\n",
      "Epoch 11/100 | val_loss: 1.08 - val_rmse: 1.04 - val_mae: 0.78 - took 0.0 sec\n",
      "Epoch 12/100 | val_loss: 1.07 - val_rmse: 1.04 - val_mae: 0.77 - took 0.0 sec\n",
      "Epoch 13/100 | val_loss: 1.06 - val_rmse: 1.03 - val_mae: 0.77 - took 0.0 sec\n",
      "Epoch 14/100 | val_loss: 1.06 - val_rmse: 1.03 - val_mae: 0.77 - took 0.0 sec\n",
      "Epoch 15/100 | val_loss: 1.05 - val_rmse: 1.02 - val_mae: 0.76 - took 0.0 sec\n",
      "Epoch 16/100 | val_loss: 1.04 - val_rmse: 1.02 - val_mae: 0.76 - took 0.0 sec\n",
      "Epoch 17/100 | val_loss: 1.03 - val_rmse: 1.02 - val_mae: 0.76 - took 0.0 sec\n",
      "Epoch 18/100 | val_loss: 1.03 - val_rmse: 1.01 - val_mae: 0.75 - took 0.0 sec\n",
      "Epoch 19/100 | val_loss: 1.02 - val_rmse: 1.01 - val_mae: 0.75 - took 0.0 sec\n",
      "Epoch 20/100 | val_loss: 1.02 - val_rmse: 1.01 - val_mae: 0.75 - took 0.0 sec\n",
      "Epoch 21/100 | val_loss: 1.01 - val_rmse: 1.01 - val_mae: 0.75 - took 0.0 sec\n",
      "Epoch 22/100 | val_loss: 1.01 - val_rmse: 1.00 - val_mae: 0.74 - took 0.0 sec\n",
      "Epoch 23/100 | val_loss: 1.00 - val_rmse: 1.00 - val_mae: 0.74 - took 0.0 sec\n",
      "Epoch 24/100 | val_loss: 1.00 - val_rmse: 1.00 - val_mae: 0.74 - took 0.0 sec\n",
      "Epoch 25/100 | val_loss: 0.99 - val_rmse: 1.00 - val_mae: 0.74 - took 0.0 sec\n",
      "Epoch 26/100 | val_loss: 0.99 - val_rmse: 0.99 - val_mae: 0.74 - took 0.0 sec\n",
      "Epoch 27/100 | val_loss: 0.98 - val_rmse: 0.99 - val_mae: 0.73 - took 0.0 sec\n",
      "Epoch 28/100 | val_loss: 0.98 - val_rmse: 0.99 - val_mae: 0.73 - took 0.0 sec\n",
      "Epoch 29/100 | val_loss: 0.98 - val_rmse: 0.99 - val_mae: 0.73 - took 0.0 sec\n",
      "Epoch 30/100 | val_loss: 0.97 - val_rmse: 0.99 - val_mae: 0.73 - took 0.0 sec\n",
      "Epoch 31/100 | val_loss: 0.97 - val_rmse: 0.98 - val_mae: 0.73 - took 0.0 sec\n",
      "Epoch 32/100 | val_loss: 0.96 - val_rmse: 0.98 - val_mae: 0.73 - took 0.0 sec\n",
      "Epoch 33/100 | val_loss: 0.96 - val_rmse: 0.98 - val_mae: 0.72 - took 0.0 sec\n",
      "Epoch 34/100 | val_loss: 0.96 - val_rmse: 0.98 - val_mae: 0.72 - took 0.0 sec\n",
      "Epoch 35/100 | val_loss: 0.95 - val_rmse: 0.98 - val_mae: 0.72 - took 0.0 sec\n",
      "Epoch 36/100 | val_loss: 0.95 - val_rmse: 0.97 - val_mae: 0.72 - took 0.0 sec\n",
      "Epoch 37/100 | val_loss: 0.95 - val_rmse: 0.97 - val_mae: 0.72 - took 0.0 sec\n",
      "Epoch 38/100 | val_loss: 0.94 - val_rmse: 0.97 - val_mae: 0.72 - took 0.0 sec\n",
      "Epoch 39/100 | val_loss: 0.94 - val_rmse: 0.97 - val_mae: 0.71 - took 0.0 sec\n",
      "Epoch 40/100 | val_loss: 0.94 - val_rmse: 0.97 - val_mae: 0.71 - took 0.0 sec\n",
      "Epoch 41/100 | val_loss: 0.93 - val_rmse: 0.97 - val_mae: 0.71 - took 0.0 sec\n",
      "Epoch 42/100 | val_loss: 0.93 - val_rmse: 0.96 - val_mae: 0.71 - took 0.0 sec\n",
      "Epoch 43/100 | val_loss: 0.93 - val_rmse: 0.96 - val_mae: 0.71 - took 0.0 sec\n",
      "Epoch 44/100 | val_loss: 0.92 - val_rmse: 0.96 - val_mae: 0.71 - took 0.0 sec\n",
      "Epoch 45/100 | val_loss: 0.92 - val_rmse: 0.96 - val_mae: 0.70 - took 0.0 sec\n",
      "Epoch 46/100 | val_loss: 0.91 - val_rmse: 0.96 - val_mae: 0.70 - took 0.0 sec\n",
      "Epoch 47/100 | val_loss: 0.91 - val_rmse: 0.95 - val_mae: 0.70 - took 0.0 sec\n",
      "Epoch 48/100 | val_loss: 0.91 - val_rmse: 0.95 - val_mae: 0.70 - took 0.0 sec\n",
      "Epoch 49/100 | val_loss: 0.90 - val_rmse: 0.95 - val_mae: 0.70 - took 0.0 sec\n",
      "Epoch 50/100 | val_loss: 0.90 - val_rmse: 0.95 - val_mae: 0.70 - took 0.0 sec\n",
      "Epoch 51/100 | val_loss: 0.89 - val_rmse: 0.95 - val_mae: 0.69 - took 0.0 sec\n",
      "Epoch 52/100 | val_loss: 0.89 - val_rmse: 0.94 - val_mae: 0.69 - took 0.0 sec\n",
      "Epoch 53/100 | val_loss: 0.89 - val_rmse: 0.94 - val_mae: 0.69 - took 0.0 sec\n",
      "Epoch 54/100 | val_loss: 0.88 - val_rmse: 0.94 - val_mae: 0.69 - took 0.0 sec\n",
      "Epoch 55/100 | val_loss: 0.88 - val_rmse: 0.94 - val_mae: 0.69 - took 0.0 sec\n",
      "Epoch 56/100 | val_loss: 0.87 - val_rmse: 0.93 - val_mae: 0.69 - took 0.0 sec\n",
      "Epoch 57/100 | val_loss: 0.87 - val_rmse: 0.93 - val_mae: 0.68 - took 0.0 sec\n",
      "Epoch 58/100 | val_loss: 0.86 - val_rmse: 0.93 - val_mae: 0.68 - took 0.0 sec\n",
      "Epoch 59/100 | val_loss: 0.86 - val_rmse: 0.93 - val_mae: 0.68 - took 0.0 sec\n",
      "Epoch 60/100 | val_loss: 0.85 - val_rmse: 0.92 - val_mae: 0.68 - took 0.0 sec\n",
      "Epoch 61/100 | val_loss: 0.85 - val_rmse: 0.92 - val_mae: 0.68 - took 0.0 sec\n",
      "Epoch 62/100 | val_loss: 0.84 - val_rmse: 0.92 - val_mae: 0.67 - took 0.0 sec\n",
      "Epoch 63/100 | val_loss: 0.84 - val_rmse: 0.92 - val_mae: 0.67 - took 0.0 sec\n",
      "Epoch 64/100 | val_loss: 0.83 - val_rmse: 0.91 - val_mae: 0.67 - took 0.0 sec\n",
      "Epoch 65/100 | val_loss: 0.83 - val_rmse: 0.91 - val_mae: 0.67 - took 0.0 sec\n",
      "Epoch 66/100 | val_loss: 0.82 - val_rmse: 0.91 - val_mae: 0.66 - took 0.0 sec\n",
      "Epoch 67/100 | val_loss: 0.82 - val_rmse: 0.90 - val_mae: 0.66 - took 0.0 sec\n",
      "Epoch 68/100 | val_loss: 0.81 - val_rmse: 0.90 - val_mae: 0.66 - took 0.0 sec\n",
      "Epoch 69/100 | val_loss: 0.81 - val_rmse: 0.90 - val_mae: 0.66 - took 0.0 sec\n",
      "Epoch 70/100 | val_loss: 0.80 - val_rmse: 0.90 - val_mae: 0.66 - took 0.0 sec\n",
      "Epoch 71/100 | val_loss: 0.80 - val_rmse: 0.89 - val_mae: 0.65 - took 0.0 sec\n",
      "Epoch 72/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.65 - took 0.0 sec\n",
      "Epoch 73/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.65 - took 0.0 sec\n",
      "Epoch 74/100 | val_loss: 0.78 - val_rmse: 0.88 - val_mae: 0.65 - took 0.0 sec\n",
      "Epoch 75/100 | val_loss: 0.78 - val_rmse: 0.88 - val_mae: 0.64 - took 0.0 sec\n",
      "Epoch 76/100 | val_loss: 0.77 - val_rmse: 0.88 - val_mae: 0.64 - took 0.0 sec\n",
      "Epoch 77/100 | val_loss: 0.76 - val_rmse: 0.87 - val_mae: 0.64 - took 0.0 sec\n",
      "Epoch 78/100 | val_loss: 0.76 - val_rmse: 0.87 - val_mae: 0.64 - took 0.0 sec\n",
      "Epoch 79/100 | val_loss: 0.75 - val_rmse: 0.87 - val_mae: 0.63 - took 0.0 sec\n",
      "Epoch 80/100 | val_loss: 0.75 - val_rmse: 0.87 - val_mae: 0.63 - took 0.0 sec\n",
      "Epoch 81/100 | val_loss: 0.74 - val_rmse: 0.86 - val_mae: 0.63 - took 0.0 sec\n",
      "Epoch 82/100 | val_loss: 0.74 - val_rmse: 0.86 - val_mae: 0.63 - took 0.0 sec\n",
      "Epoch 83/100 | val_loss: 0.73 - val_rmse: 0.86 - val_mae: 0.62 - took 0.0 sec\n",
      "Epoch 84/100 | val_loss: 0.73 - val_rmse: 0.85 - val_mae: 0.62 - took 0.0 sec\n",
      "Epoch 85/100 | val_loss: 0.72 - val_rmse: 0.85 - val_mae: 0.62 - took 0.0 sec\n",
      "Epoch 86/100 | val_loss: 0.72 - val_rmse: 0.85 - val_mae: 0.62 - took 0.0 sec\n",
      "Epoch 87/100 | val_loss: 0.71 - val_rmse: 0.84 - val_mae: 0.61 - took 0.0 sec\n",
      "Epoch 88/100 | val_loss: 0.71 - val_rmse: 0.84 - val_mae: 0.61 - took 0.0 sec\n",
      "Epoch 89/100 | val_loss: 0.70 - val_rmse: 0.84 - val_mae: 0.61 - took 0.0 sec\n",
      "Epoch 90/100 | val_loss: 0.70 - val_rmse: 0.84 - val_mae: 0.61 - took 0.0 sec\n",
      "Epoch 91/100 | val_loss: 0.69 - val_rmse: 0.83 - val_mae: 0.60 - took 0.0 sec\n",
      "Epoch 92/100 | val_loss: 0.69 - val_rmse: 0.83 - val_mae: 0.60 - took 0.0 sec\n",
      "Epoch 93/100 | val_loss: 0.68 - val_rmse: 0.83 - val_mae: 0.60 - took 0.0 sec\n",
      "Epoch 94/100 | val_loss: 0.68 - val_rmse: 0.82 - val_mae: 0.60 - took 0.0 sec\n",
      "Epoch 95/100 | val_loss: 0.67 - val_rmse: 0.82 - val_mae: 0.60 - took 0.0 sec\n",
      "Epoch 96/100 | val_loss: 0.67 - val_rmse: 0.82 - val_mae: 0.59 - took 0.0 sec\n",
      "Epoch 97/100 | val_loss: 0.66 - val_rmse: 0.82 - val_mae: 0.59 - took 0.0 sec\n",
      "Epoch 98/100 | val_loss: 0.66 - val_rmse: 0.81 - val_mae: 0.59 - took 0.0 sec\n",
      "Epoch 99/100 | val_loss: 0.66 - val_rmse: 0.81 - val_mae: 0.59 - took 0.0 sec\n",
      "Epoch 100/100 | val_loss: 0.65 - val_rmse: 0.81 - val_mae: 0.58 - took 0.0 sec\n",
      "\n",
      "Training took 3 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<funk_svd.svd.SVD at 0x2afed33b2198>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(lr=0.001, reg=0.005, n_epochs=100, n_factors=15,\n",
    "         early_stopping=True, shuffle=False, min_rating=1, max_rating=5)\n",
    "svd.fit(X=df, X_val=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_real=MF(data=R, learning_rate=0.01,latent_features=3,beta=0.01,iterations=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_real.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_real.whole_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.random.randint(low=1,high=2,size=(3,2))\n",
    "s1=np.random.uniform(low=5,high=20,size=(2,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1[:,0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "            (i, j, an[i, j])\n",
    "            for i in range(3)\n",
    "            for j in range(3)\n",
    "        ]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((p-an)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an=np.matmul(s,s1)\n",
    "an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_validate(SVD(), data, measures=['RMSE'], cv=3, verbose=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD(n_factors=10, n_epochs=10)\n",
    "model = algo.fit(trainset)\n",
    "accuracy.rmse(predictions)\n",
    "#pred = algo.predict(str(196) , str(302), r_ui=4, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sample=df1[df1['anonymous_user_id'].isin(s['anonymous_user_id'])]\n",
    "#print(df_sample.shape)\n",
    "matrix = df.pivot_table(index='anonymous_user_id', columns='movie_id', values='converted_rating')\n",
    "print(matrix.shape)\n",
    "matrix.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_similarity = matrix.T.corr()\n",
    "user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picked_userid = 5\n",
    "# Remove picked user ID from the candidate list\n",
    "user_similarity.drop(index=picked_userid, inplace=True)\n",
    "# Take a look at the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "# User similarity threashold\n",
    "user_similarity_threshold = 0\n",
    "# Get top n similar users\n",
    "similar_users = user_similarity[user_similarity[picked_userid]>user_similarity_threshold][picked_userid].sort_values(ascending=False)[:n]\n",
    "# Print out top n similar users\n",
    "#print(f'The similar users for user {picked_userid} are', similar_users)\n",
    "similar_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picked_userid_watched = matrix[matrix.index == picked_userid].dropna(axis=1, how='all')\n",
    "picked_userid_watched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_user_movies = matrix[matrix.index.isin(similar_users.index)].dropna(axis=1, how='all')\n",
    "similar_user_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_user_movies.drop(picked_userid_watched.columns,axis=1, inplace=True, errors='ignore')\n",
    "# Take a look at the data\n",
    "similar_user_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_score = {}\n",
    "for i in similar_user_movies.columns:\n",
    "    movie_rating = similar_user_movies[i]\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for u in similar_users.index:\n",
    "        if pd.isna(movie_rating[u]) == False:\n",
    "            score = similar_users[u] * movie_rating[u]\n",
    "            total += score\n",
    "            count +=1\n",
    "    item_score[i] = total / count\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_score = pd.DataFrame(item_score.items(), columns=['movie', 'movie_score'])\n",
    "init_rating = item_score.sort_values(by='movie_score', ascending=False)\n",
    "# Select top m movies\n",
    "init_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating = matrix[matrix.index == picked_userid].T.mean()[picked_userid]\n",
    "init_rating['predicted_rating'] = init_rating['movie_score'] + avg_rating\n",
    "# Take a look at the data\n",
    "init_rating.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
